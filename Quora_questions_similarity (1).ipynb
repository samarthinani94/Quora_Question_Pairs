{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.369197853026293"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_duplicate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['question1','question2','is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['x1','x2','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))] #x is train_toy['x1'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset in train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['x1','x2']].values\n",
    "y = np.array(train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Is this a German Shepherd dog?',\n",
       "       'Are german shepherd dogs loyal?'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for x1,x2 in content:\n",
    "        line = str(x1)+' '+str(x2)\n",
    "        words = set(line.split())\n",
    "        for word in words:\n",
    "            vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = get_vocab(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in word_count:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = word_count.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile='data/glove.6B.100d.txt'):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rare_words(word_vecs, word_count, min_df=4):\n",
    "    \"\"\" Deletes rare words from word_count\n",
    "    \n",
    "    Deletes words from word_count if they are not in word_vecs\n",
    "    and don't have at least min_df occurrencies in word_count.\n",
    "    \"\"\"\n",
    "    words_delete = []\n",
    "    for word in word_count:\n",
    "        if word_count[word] < min_df and word not in word_vecs:\n",
    "            words_delete.append(word)\n",
    "    for word in words_delete: word_count.pop(word)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_vecs, word_count, min_df=4, emb_size=100):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    word_count = delete_rare_words(word_vecs, word_count, min_df)\n",
    "    V = len(word_count.keys()) + 2\n",
    "    vocab2index = {}\n",
    "    W = np.zeros((V, emb_size), dtype=\"float32\")\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    # adding a vector for padding\n",
    "    W[0] = np.zeros(emb_size, dtype='float32')\n",
    "    # adding a vector for rare words \n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    vocab2index[\"UNK\"] = 1\n",
    "    vocab2index[\"\"] = 0\n",
    "    i = 2\n",
    "    for word in word_count:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1   \n",
    "    return W, np.array(vocab), vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weight, vocab, vocab2index = create_embedding_matrix(word_vecs, word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence_with_padding(sentences, vocab2index):\n",
    "    s1,s2 = sentences\n",
    "    s1 = spacy_tok(str(s1))\n",
    "    s2 = spacy_tok(str(s2))\n",
    "    if len(s1) >= len(s2):\n",
    "        s2 = s2 + [\"\" for _ in range(len(s1)-len(s2))]\n",
    "    else:\n",
    "        s1 = s1 + [\"\" for _ in range(len(s2)-len(s1))]\n",
    "    return np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in s1]),np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.temp = [encode_sentence_with_padding(sentence, vocab2index) for sentence in X]\n",
    "        self.x1 = [v[0] for v in self.temp]\n",
    "        self.x2 = [v[1] for v in self.temp]\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x1[idx],self.x2[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = QuoraDataset(X_train, y_train)\n",
    "valid_ds = QuoraDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (sentences, labels).\n",
    "    \n",
    "    Need custom collate_fn because merging sequences (including padding) is not \n",
    "    supported in default. Sequences are padded to the maximum length of mini-batch \n",
    "    sequences (dynamic padding).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (sentence, label). \n",
    "            - list of word indices of variable length\n",
    "            - label, 0 or 1\n",
    "    Returns:\n",
    "        packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "        sencences: torch tensor of shape (batch_size, max_len).\n",
    "        labels: torch tensor of shape (batch_size, 1).\n",
    "        lengths: list; valid length for each padded sentence. \n",
    "    \"\"\"\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    s1,s2, labels = zip(*data)\n",
    "    \n",
    "    # stack labels\n",
    "    labels = torch.Tensor(labels)\n",
    "    \n",
    "    # Merge sentences\n",
    "    lengths = [len(s) for s in s1]\n",
    "   \n",
    "    sents1 = torch.zeros(len(s1), max(lengths)).long()\n",
    "    for i, s in enumerate(s1):\n",
    "        end = lengths[i]\n",
    "        sents1[i, :end] = torch.Tensor(s[:end]) \n",
    "        \n",
    " \n",
    "    sents2 = torch.zeros(len(s2), max(lengths)).long()\n",
    "    for i, s in enumerate(s2):\n",
    "        end = lengths[i]\n",
    "        sents2[i, :end] = torch.Tensor(s[:end])        \n",
    "    \n",
    "    return sents1, sents2, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations, div_start=5, div_end=5):\n",
    "    min_start, min_end = max_lr/div_start, max_lr/div_end\n",
    "    iter1 = int(0.3*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 100000\n",
    "lr = get_cosine_triangular_lr(0.01, N)\n",
    "plt.plot(list(range(N)), lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim_1,hidden_dim_2,glove_weights=None) :\n",
    "        super(GRUModel,self).__init__()\n",
    "        self.hidden_dim_1 = hidden_dim_1\n",
    "        self.embeddings_1 = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if glove_weights is not None:\n",
    "            self.embeddings_1.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "            self.embeddings_1.weight.requires_grad = False ## freeze embeddings           \n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim_1, batch_first=True)\n",
    "        self.linear_1 = nn.Linear(hidden_dim_1, 10)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        self.hidden_dim_2 = hidden_dim_2\n",
    "        self.linear_2 = nn.Linear(hidden_dim_2, 10)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        \n",
    "    def forward(self, x1,x2, lengths):\n",
    "        x1 = self.embeddings_1(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        x2 = self.embeddings_1(x2)\n",
    "        x2 = self.dropout(x2)\n",
    "        pack_1 = pack_padded_sequence(x1, lengths, batch_first=True)\n",
    "        out_pack_1, ht_1 = self.gru(pack_1)\n",
    "        pack_2 = pack_padded_sequence(x2, lengths, batch_first=True)\n",
    "        out_pack_2, ht_2 = self.gru(pack_2)\n",
    "        x1 = self.linear_1(ht_1[-1])\n",
    "        x2 = self.linear_2(ht_2[-1])\n",
    "#         x = torch.cosine_similarity([x1,x2],1)\n",
    "        return self.cos(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, valid_dl,max_lr=0.05, epochs=10):\n",
    "    iterations = epochs*len(train_dl)\n",
    "    idx = 0\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    best_val_acc = 0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x1, x2, s, y in train_dl:\n",
    "            x1 = x1.long().cuda()\n",
    "            x2 = x2.long().cuda()\n",
    "#             s = s.long.cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred = model(x1,x2,s)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx +=1\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))  \n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            path = \"models/model_acc_{0:.3f}_model1_all_cat.pth\".format(100*val_acc) \n",
    "            save_model(model, path)\n",
    "            print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x1,x2, s, y in valid_dl:\n",
    "        x1 = x1.long().cuda()\n",
    "        x2 = x2.long().cuda()\n",
    "#         s = s.long.cuda()\n",
    "        y = y.float().cuda()\n",
    "        y_hat = model(x1,x2, s)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_results(model, test_dl):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "#     idx = []\n",
    "    for x1,x2, s, y in test_dl:\n",
    "        x1 = x1.long().cuda()\n",
    "        x2 = x2.long().cuda()\n",
    "#         s = s.long.cuda()\n",
    "        y = y.float().cuda()\n",
    "        y_hat = model(x1,x2, s)\n",
    "        y_pred = y_hat > 0\n",
    "        ys.append(int(y_pred.cpu()))\n",
    "#     idx = np.arange(len(ys))\n",
    "#     pd.\n",
    "            \n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(vocab_size=vocab.shape[0],\n",
    "                 embedding_dim=100,\n",
    "                 hidden_dim_1=100,hidden_dim_2=100, glove_weights=pretrained_weight).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.02, weight_decay=1e-4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_acc_68.252_model1_all_cat.pth\n",
      "train loss 0.608 val loss 0.590 and val accuracy 0.702\n",
      "models/model_acc_70.165_model1_all_cat.pth\n",
      "train loss 0.598 val loss 0.576 and val accuracy 0.718\n",
      "models/model_acc_71.771_model1_all_cat.pth\n",
      "models/model_acc_72.251_model1_all_cat.pth\n",
      "train loss 0.577 val loss 0.572 and val accuracy 0.722\n",
      "models/model_acc_72.375_model1_all_cat.pth\n",
      "train loss 0.573 val loss 0.577 and val accuracy 0.715\n",
      "models/model_acc_73.353_model1_all_cat.pth\n",
      "train loss 0.568 val loss 0.558 and val accuracy 0.739\n",
      "models/model_acc_73.932_model1_all_cat.pth\n",
      "train loss 0.568 val loss 0.563 and val accuracy 0.732\n",
      "train loss 0.563 val loss 0.557 and val accuracy 0.740\n",
      "models/model_acc_73.986_model1_all_cat.pth\n",
      "models/model_acc_74.375_model1_all_cat.pth\n",
      "train loss 0.561 val loss 0.557 and val accuracy 0.742\n",
      "train loss 0.567 val loss 0.557 and val accuracy 0.741\n",
      "models/model_acc_74.700_model1_all_cat.pth\n",
      "train loss 0.559 val loss 0.550 and val accuracy 0.751\n",
      "models/model_acc_75.133_model1_all_cat.pth\n",
      "train loss 0.561 val loss 0.550 and val accuracy 0.750\n",
      "train loss 0.560 val loss 0.560 and val accuracy 0.737\n",
      "train loss 0.558 val loss 0.550 and val accuracy 0.751\n",
      "train loss 0.557 val loss 0.550 and val accuracy 0.751\n",
      "models/model_acc_75.180_model1_all_cat.pth\n",
      "train loss 0.559 val loss 0.549 and val accuracy 0.754\n",
      "models/model_acc_75.419_model1_all_cat.pth\n",
      "models/model_acc_75.453_model1_all_cat.pth\n",
      "train loss 0.556 val loss 0.548 and val accuracy 0.753\n",
      "train loss 0.562 val loss 0.548 and val accuracy 0.753\n",
      "train loss 0.557 val loss 0.547 and val accuracy 0.755\n",
      "models/model_acc_75.532_model1_all_cat.pth\n",
      "train loss 0.556 val loss 0.547 and val accuracy 0.755\n",
      "train loss 0.560 val loss 0.548 and val accuracy 0.753\n",
      "train loss 0.560 val loss 0.555 and val accuracy 0.744\n",
      "models/model_acc_75.604_model1_all_cat.pth\n",
      "train loss 0.555 val loss 0.548 and val accuracy 0.754\n",
      "train loss 0.555 val loss 0.569 and val accuracy 0.727\n",
      "train loss 0.553 val loss 0.555 and val accuracy 0.746\n",
      "train loss 0.554 val loss 0.556 and val accuracy 0.745\n",
      "train loss 0.553 val loss 0.548 and val accuracy 0.754\n",
      "train loss 0.552 val loss 0.545 and val accuracy 0.757\n",
      "models/model_acc_75.739_model1_all_cat.pth\n",
      "train loss 0.553 val loss 0.546 and val accuracy 0.756\n",
      "train loss 0.554 val loss 0.545 and val accuracy 0.758\n",
      "models/model_acc_75.771_model1_all_cat.pth\n",
      "models/model_acc_75.860_model1_all_cat.pth\n",
      "train loss 0.553 val loss 0.569 and val accuracy 0.729\n",
      "train loss 0.553 val loss 0.545 and val accuracy 0.756\n",
      "train loss 0.554 val loss 0.550 and val accuracy 0.750\n",
      "train loss 0.555 val loss 0.546 and val accuracy 0.757\n",
      "train loss 0.555 val loss 0.546 and val accuracy 0.756\n",
      "train loss 0.551 val loss 0.544 and val accuracy 0.761\n",
      "models/model_acc_76.054_model1_all_cat.pth\n",
      "train loss 0.553 val loss 0.547 and val accuracy 0.757\n",
      "train loss 0.553 val loss 0.545 and val accuracy 0.757\n",
      "train loss 0.552 val loss 0.544 and val accuracy 0.758\n",
      "train loss 0.553 val loss 0.549 and val accuracy 0.752\n",
      "train loss 0.552 val loss 0.545 and val accuracy 0.757\n",
      "train loss 0.551 val loss 0.550 and val accuracy 0.752\n",
      "train loss 0.553 val loss 0.550 and val accuracy 0.751\n",
      "train loss 0.557 val loss 0.545 and val accuracy 0.758\n",
      "train loss 0.553 val loss 0.548 and val accuracy 0.755\n",
      "train loss 0.551 val loss 0.547 and val accuracy 0.755\n",
      "train loss 0.553 val loss 0.545 and val accuracy 0.757\n",
      "train loss 0.550 val loss 0.544 and val accuracy 0.759\n",
      "train loss 0.551 val loss 0.546 and val accuracy 0.756\n",
      "train loss 0.551 val loss 0.551 and val accuracy 0.750\n",
      "train loss 0.550 val loss 0.547 and val accuracy 0.755\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = GRUModel(vocab_size=vocab.shape[0],\n",
    "                 embedding_dim=100,\n",
    "                 hidden_dim_1=100,hidden_dim_2=100, glove_weights=pretrained_weight).cuda() \n",
    "load_model(test_model, 'models/model_acc_76.054_model1_all_cat.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['question1','question2','y']]\n",
    "test.columns = ['x1','x2','y']\n",
    "X_test = test[['x1','x2']].values\n",
    "y_test = np.array(test['y'])\n",
    "test_ds = QuoraDataset(X_test,y_test)\n",
    "test_dl = DataLoader(test_ds, shuffle=False,collate_fn=collate_fn, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "ys = test_results(test_model,test_dl)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649027848243713\n"
     ]
    }
   ],
   "source": [
    "print((t2-t1)/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predictions'] = ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['index'] = range(len(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['index','predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_results_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  predictions\n",
       "0      0            0\n",
       "1      1            0\n",
       "2      2            0\n",
       "3      3            0\n",
       "4      4            0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = ['test_id','is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
